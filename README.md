# IrisDataWithDiferentModels
# ğŸŒ¸ Iris Dataset Classification & Regression Analysis

Bu proje, klasik **Iris veri seti** Ã¼zerinde farklÄ± makine Ã¶ÄŸrenimi algoritmalarÄ±nÄ±n performanslarÄ±nÄ± karÅŸÄ±laÅŸtÄ±rmak iÃ§in hazÄ±rlanmÄ±ÅŸtÄ±r.  
AmaÃ§, hem **sÄ±nÄ±flandÄ±rma (Naive Bayes)** hem de **regresyon (Linear Regression & SVR)** yÃ¶ntemlerini uygulayÄ±p deÄŸerlendirmektir.

---

##  Ä°Ã§indekiler
- [Proje AmacÄ±](#proje-amacÄ±)
- [Veri KeÅŸfi (EDA)](#veri-keÅŸfi-eda)
- [Modelleme AÅŸamalarÄ±](#modelleme-aÅŸamalarÄ±)
  - Gaussian Naive Bayes
  - Linear Regression
  - Support Vector Regression (SVR)
  - SVR + GridSearchCV (Hyperparameter Tuning)
- [SonuÃ§lar](#sonuÃ§lar)
- [Yorum ve Ã‡Ä±karÄ±mlar](#yorum-ve-Ã§Ä±karÄ±mlar)
- [Yazar](#yazar)

---

## ğŸ¯ Proje AmacÄ±

Bu Ã§alÄ±ÅŸmada aÅŸaÄŸÄ±daki sorulara yanÄ±t aranmÄ±ÅŸtÄ±r:
1. Iris Ã§iÃ§ek tÃ¼rlerini (setosa, versicolor, virginica) sÄ±nÄ±flandÄ±rmak iÃ§in hangi model daha etkilidir?  
2. Sepal/Petal uzunluk ve geniÅŸlikleri Ã¼zerinden doÄŸrusal ve doÄŸrusal olmayan regresyon modelleri nasÄ±l sonuÃ§ verir?  
3. GridSearchCV ile hiperparametre optimizasyonu modeli ne kadar iyileÅŸtirir?

---

ğŸ” Veri KeÅŸfi (EDA)

KullanÄ±lan veri: 11-iris.csv

150 Ã¶rnek, 5 nitelik:

SepalLengthCm

SepalWidthCm

PetalLengthCm

PetalWidthCm

Species (hedef)

TÃ¼r	Ã–rnek SayÄ±sÄ±
Iris-setosa	50
Iris-versicolor	50
Iris-virginica	50
ğŸ“Š GÃ¶rselleÅŸtirme

Pairplot grafikleri: tÃ¼rler arasÄ±nda PetalLength ve PetalWidth deÄŸiÅŸkenlerinin gÃ¼Ã§lÃ¼ ayÄ±rt edici olduÄŸunu gÃ¶steriyor.

Scatter plotâ€™larda Iris-setosa net ayrÄ±lÄ±rken, versicolor ve virginica kÄ±smen Ã¶rtÃ¼ÅŸÃ¼yor.

ğŸ¤– Modelleme AÅŸamalarÄ±
1ï¸âƒ£ Gaussian Naive Bayes (Classification)
gnb = GaussianNB()
gnb.fit(X_train_scaled, y_train)
y_pred = gnb.predict(X_test_scaled)


SonuÃ§lar:

Metrik	DeÄŸer
Accuracy	1.0 (100%)
Precision	1.00
Recall	1.00
F1-score	1.00

âœ… TÃ¼m sÄ±nÄ±flar mÃ¼kemmel biÃ§imde sÄ±nÄ±flandÄ±rÄ±lmÄ±ÅŸtÄ±r.
Bu, Iris veri setinin Naive Bayes ile oldukÃ§a kolay ayrÄ±labildiÄŸini gÃ¶sterir.

2ï¸âƒ£ Linear Regression (Regression)
linreg = LinearRegression()
linreg.fit(X_train_scaled, y_train)


SonuÃ§lar:

Metrik	DeÄŸer
Mean Absolute Error	0.1572
RÂ² Score	0.9339

ğŸ“ˆ Model, verideki varyansÄ±n %93â€™Ã¼nÃ¼ aÃ§Ä±klayabiliyor.

3ï¸âƒ£ Support Vector Regression (SVR)
svr = SVR()
svr.fit(X_train_scaled, y_train)


SonuÃ§lar:

Metrik	DeÄŸer
Mean Absolute Error	0.1370
RÂ² Score	0.9528

RBF kernel sayesinde doÄŸrusal olmayan iliÅŸkilere daha iyi uyum saÄŸlamÄ±ÅŸ.
RÂ² deÄŸeri Linear Regressionâ€™a gÃ¶re biraz daha yÃ¼ksek.

4ï¸âƒ£ SVR + GridSearchCV (Hyperparameter Optimization)
param_grid = {
    'C': [0.1, 1, 10, 100, 1000],
    'gamma': [1, 0.1, 0.01, 0.001, 0.0001],
    'kernel': ['rbf', 'linear']
}
grid = GridSearchCV(SVR(), param_grid, refit=True, verbose=3, n_jobs=-1)


En iyi parametreler:

{'C': 1, 'gamma': 0.1, 'kernel': 'rbf'}


SonuÃ§lar:

Metrik	DeÄŸer
Mean Absolute Error	0.1319
RÂ² Score	0.9498

GridSearchCV sonrasÄ± skorlar benzer kaldÄ±; model zaten optimizeye oldukÃ§a yakÄ±ndÄ±.

ğŸ“ˆ SonuÃ§ KarÅŸÄ±laÅŸtÄ±rma Tablosu
Model	TÃ¼r	Accuracy / RÂ²	MAE	AÃ§Ä±klama
GaussianNB	Classification	1.00	â€“	TÃ¼m tÃ¼rleri hatasÄ±z ayÄ±rdÄ±
Linear Regression	Regression	0.9339	0.157	DoÄŸrusal iliÅŸki gÃ¼Ã§lÃ¼
SVR	Regression	0.9528	0.137	RBF kernel ile daha iyi sonuÃ§
SVR (GridSearchCV)	Regression	0.9498	0.132	Parametre ayarÄ±yla minimal iyileÅŸme

